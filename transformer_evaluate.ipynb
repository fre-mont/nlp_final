{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","import json\n","import sentencepiece as spm\n","from model import Transformer, Encoder, Decoder\n","import os "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Transformer(\n","  (encoder): Encoder(\n","    (tok_embedding): Embedding(4000, 256)\n","    (pos_embedding): Embedding(500, 256)\n","    (layers): ModuleList(\n","      (0-5): 6 x EncoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (tok_embedding): Embedding(4000, 256)\n","    (pos_embedding): Embedding(500, 256)\n","    (layers): ModuleList(\n","      (0-5): 6 x DecoderLayer(\n","        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder_attention): MultiHeadAttentionLayer(\n","          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n","          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n","          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (fc_out): Linear(in_features=256, out_features=4000, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n",")\n"]}],"source":["model_path = 'model/transformer/last_model.pth'\n","config_path = os.path.join(os.path.dirname(model_path), 'configuration.json')\n","\n","# 설정 로드\n","with open(config_path, 'r') as f:\n","    config = json.load(f)\n","\n","# SentencePiece 모델 로드\n","sp = spm.SentencePieceProcessor()\n","sp.Load(f'data/bpe_4000.model')\n","\n","# 모델 로드\n","device = torch.device('cuda:0')\n","num_vocab = sp.get_piece_size()\n","\n","encoder = Encoder(\n","    input_dim=num_vocab,\n","    hidden_dim=config['hidden_dim'],\n","    n_layers=config['enc_layer'],\n","    n_heads=config['enc_head'],\n","    pf_dim=512,\n","    dropout_ratio=0.1,\n","    device=device)\n","\n","decoder = Decoder(\n","    output_dim=num_vocab,\n","    hidden_dim=config['hidden_dim'],\n","    n_layers=config['dec_layer'],\n","    n_heads=config['dec_head'],\n","    pf_dim=512,\n","    dropout_ratio=0.1,\n","    device=device)\n","\n","model = Transformer(\n","    encoder,\n","    decoder,\n","    sp.pad_id(),\n","    sp.pad_id(),\n","    device\n",").to(device)\n","\n","ckpt = torch.load(model_path)\n","model.load_state_dict(ckpt)\n","print(model)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":654},"executionInfo":{"elapsed":2608,"status":"ok","timestamp":1716943974255,"user":{"displayName":"서가연","userId":"09789171349553603896"},"user_tz":-540},"id":"LAlUGuZQ0vQH","outputId":"f699b13c-5392-46e5-9b48-8ca2e6cba1ee"},"outputs":[],"source":["\n","def convert_to_sentence(token_list):\n","    # '▁' 문자를 공백으로 변환하여 문장을 만듭니다.\n","    sentence = ''.join([token.replace('▁', ' ') for token in token_list if token != '<eos>'])\n","    # 앞뒤 공백을 제거하고 반환합니다.\n","    return sentence.strip()\n","\n","\n","def inference(txt):\n","    model.eval()\n","    with torch.no_grad():\n","        seq = sp.encode_as_ids(txt)\n","        seq = torch.cat((\n","            torch.tensor([sp.bos_id()]),\n","            torch.tensor(seq),\n","            torch.tensor([sp.eos_id()])\n","        ))\n","        src = seq.unsqueeze(0).to(device)\n","        src_mask = model.make_src_mask(src)\n","        enc_src = model.encoder(src, src_mask)\n","        tgt_indices = [sp.bos_id()]\n","\n","        \n","        for _ in range(500):\n","            tgt_tensor = torch.LongTensor(tgt_indices).unsqueeze(0).to(device)\n","            tgt_mask = model.make_tgt_mask(tgt_tensor)\n","            output, attention = model.decoder(tgt_tensor, enc_src, tgt_mask, src_mask)\n","            pred_token = output.argmax(2)[:,-1].item()\n","            tgt_indices.append(pred_token)\n","\n","            if pred_token == sp.eos_id():\n","                break\n","\n","        translate = sp.id_to_piece(tgt_indices[1:])\n","        copy = sp.id_to_piece(src[0].tolist()[1:-1])\n","\n","        return convert_to_sentence(translate)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"IZb9zjip5tfG"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력 : 하영 속았수다\n","번역 : 많이 고생했습니다\n"]}],"source":["input_text = '하영 속았수다'\n","output_text = inference(input_text)\n","print(f'입력 : {input_text}')\n","print(f'번역 : {output_text}')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN/M1s9tCxiVEthWwTrkza+","gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
